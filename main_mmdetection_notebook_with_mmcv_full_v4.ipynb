{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShirCohen1/mmdetection/blob/master/main_mmdetection_notebook_with_mmcv_full_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17AVe-A6Clog"
      },
      "source": [
        "# Run below for all setup\n",
        "- ETA > 30 min\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i16HTIRxVM3V"
      },
      "source": [
        "## Using Colab Pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htZ2zBaX4BEZ",
        "outputId": "a5b8a20a-2fba-429c-eee6-fb9efe1090ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPcJsWZAuXUp",
        "outputId": "5bda5634-efec-4b8b-f7b0-1f72526b3b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 22 06:44:18 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    39W / 300W |    596MiB / 16384MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-iffKA-up0g",
        "outputId": "57575c0b-5249-48ef-b1ae-6a48eec81519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gYaRY7PkGby"
      },
      "source": [
        "## Github Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o1W2kCI_kPr7"
      },
      "outputs": [],
      "source": [
        "#update your details\n",
        "!git config --global user.name = \"ShirCohen1\"\n",
        "!git config --global user.email = \"shirc1712@gmail.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5q-8PIuqOmYQ"
      },
      "outputs": [],
      "source": [
        "# token = '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'\n",
        "# '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'\n",
        "token = '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'\n",
        "username = 'ShirCohen1'\n",
        "repo = 'mmcv-full'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQUXIoJAPRTk",
        "outputId": "29c6262b-37ef-4856-ee1a-ac7b33267c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmcv-full'...\n",
            "remote: Enumerating objects: 816, done.\u001b[K\n",
            "remote: Counting objects: 100% (816/816), done.\u001b[K\n",
            "remote: Compressing objects: 100% (684/684), done.\u001b[K\n",
            "remote: Total 816 (delta 234), reused 672 (delta 126), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (816/816), 772.49 KiB | 11.53 MiB/s, done.\n",
            "Resolving deltas: 100% (234/234), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://{token}@github.com/{username}/{repo} #https://github.com/ShirCohen1/mmcv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMF1WB0kDrsi",
        "outputId": "81a35cef-207b-4aed-f7e5-cf0c6d3ce838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmcv-full\n"
          ]
        }
      ],
      "source": [
        "%cd mmcv-full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIgvJHITDm3f",
        "outputId": "5d47cc35-5785-4ea7-bd10-7c6b76b2dac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mmcv-full\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv-full==1.7.1)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.1) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.1) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.1) (8.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.1) (6.0)\n",
            "Collecting yapf (from mmcv-full==1.7.1)\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata>=6.6.0 (from yapf->mmcv-full==1.7.1)\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting platformdirs>=3.5.1 (from yapf->mmcv-full==1.7.1)\n",
            "  Downloading platformdirs-3.7.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full==1.7.1) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full==1.7.1) (3.15.0)\n",
            "Installing collected packages: addict, platformdirs, importlib-metadata, yapf, mmcv-full\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 3.3.0\n",
            "    Uninstalling platformdirs-3.3.0:\n",
            "      Successfully uninstalled platformdirs-3.3.0\n",
            "  Running setup.py develop for mmcv-full\n",
            "Successfully installed addict-2.4.0 importlib-metadata-6.7.0 mmcv-full-1.7.1 platformdirs-3.7.0 yapf-0.40.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -e . # around ~40 min to run 21:46-22:22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSjNOKvbkWbm",
        "outputId": "49a0770b-3ab1-4b72-ba6c-eaf4ceac5ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbuild\u001b[0m/   LICENSES.md  \u001b[01;34mmmcv\u001b[0m/                PKG-INFO   \u001b[01;34mrequirements\u001b[0m/  setup.py\n",
            "LICENSE  MANIFEST.in  \u001b[01;34mmmcv_full.egg-info\u001b[0m/  README.md  setup.cfg\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1sShYN7SkRcj"
      },
      "outputs": [],
      "source": [
        "# token = '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'\n",
        "# username = 'ShirCohen1'\n",
        "repo = 'mmdetection'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyA0fpJUkSwi",
        "outputId": "35193b30-a8ea-407f-c6a8-a360e6e9072c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 25678, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 25678 (delta 38), reused 64 (delta 35), pack-reused 25606\u001b[K\n",
            "Receiving objects: 100% (25678/25678), 59.40 MiB | 34.92 MiB/s, done.\n",
            "Resolving deltas: 100% (17568/17568), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://{token}@github.com/{username}/{repo} #https://github.com/ShirCohen1/mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySjWWnOTvdrY",
        "outputId": "c151aae8-1cc3-41b2-e8f7-bde8e7ffa417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmcv-full/mmdetection\n"
          ]
        }
      ],
      "source": [
        "%cd mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZBO_yejcftV",
        "outputId": "0891a0fd-7f48-4da4-87e3-5c8c3a9bd537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mmcv-full/mmdetection\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (1.22.4)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (2.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (1.16.0)\n",
            "Collecting terminaltables (from mmdet==2.28.2)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (2.8.2)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.28.2 terminaltables-3.1.10\n"
          ]
        }
      ],
      "source": [
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oW_JhizyRJV"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtXfWabCZ0lY",
        "outputId": "d73b02e7-7e09-4710-bb7f-1a68437ba32d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmcv-full\n"
          ]
        }
      ],
      "source": [
        "%cd -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM1UIoZHc8MK"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiDrvf770gm6",
        "outputId": "026f5371-d139-4bed-d028-9e6677bc261b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaKpkVXufxl6"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHmUMWaYfHim",
        "outputId": "f5e949a2-be14-4999-813c-88f9a19e249d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4iAVVpVflGD",
        "outputId": "e09ffeea-ce65-4e4f-fd3d-c6bdc048635f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu111 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0+cu111\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYeTgZ1M0EZz"
      },
      "outputs": [],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9mME25Ofuw-",
        "outputId": "ac282933-e301-4800-be23-95eb9534c4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118 True\n",
            "2.28.2\n",
            "11.8\n",
            "GCC 9.4\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "# import mmdet\n",
        "import mmdetection.mmdet as mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvhnggBti3qG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbP7GQjU04ed"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-1P12es09jv",
        "outputId": "a8178f82-278a-4438-e0b2-31b86763b493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmcv-full/mmdetection\n"
          ]
        }
      ],
      "source": [
        "%cd mmdetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ6Qy2_9fF9l"
      },
      "source": [
        "## Download and Load Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4e_l1pRgGug",
        "outputId": "813063fd-43d6-4b4f-d4e4-5e5567c7fa3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-22 07:21:34--  https://download.openmmlab.com/mmdetection/v2.0/yolo/yolov3_d53_320_273e_coco/yolov3_d53_320_273e_coco-421362b6.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 8.48.85.212, 8.48.85.208, 8.48.85.211, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|8.48.85.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248091419 (237M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/yolov3_d53_320_273e_coco-421362b6.pth’\n",
            "\n",
            "checkpoints/yolov3_ 100%[===================>] 236.60M  12.7MB/s    in 19s     \n",
            "\n",
            "2023-06-22 07:21:53 (12.6 MB/s) - ‘checkpoints/yolov3_d53_320_273e_coco-421362b6.pth’ saved [248091419/248091419]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We download the pre-trained checkpoints for inference and finetuning.\n",
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/yolo/yolov3_d53_320_273e_coco/yolov3_d53_320_273e_coco-421362b6.pth \\\n",
        "      -O checkpoints/yolov3_d53_320_273e_coco-421362b6.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxu1-E2tjIMq"
      },
      "outputs": [],
      "source": [
        "# Copy pre separated data from drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZsas9-YkoRu"
      },
      "outputs": [],
      "source": [
        "# Load existing annotation files\n",
        "# To create new annotation files (not in drive) run in pycharm\n",
        "!mkdir data/\n",
        "!mkdir data/coco/\n",
        "!mkdir data/coco/cityscapes\n",
        "\n",
        "# daniel drive\n",
        "%cp -r -av \"/content/gdrive/MyDrive/Final_Project/data/coco/cityscapes/annotations\" \"/content/mmcv-full/mmdetection/data/coco/cityscapes\"\n",
        "%cp -r -av \"/content/gdrive/MyDrive/Final_Project/data/aachen_000000_000019_leftImg8bit.png\" \"/content/mmcv-full/mmdetection/demo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPQcqqENmsde"
      },
      "outputs": [],
      "source": [
        "# Load images for training\n",
        "!mkdir data/coco/cityscapes/\n",
        "!mkdir data/coco/cityscapes/leftImg8bit\n",
        "\n",
        "# daniel drive\n",
        "%cp -r -av \"/content/gdrive/MyDrive/Final_Project/data/coco/cityscapes/leftImg8bit\" \"/content/mmcv-full/mmdetection/data/coco/cityscapes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFBvCeLfjgUA"
      },
      "outputs": [],
      "source": [
        "# # train annotation file\n",
        "# f = open('data/coco/cityscapes/annotations/instancesonly_filtered_gtFine_train_exp1.json')\n",
        "# train = json.load(f)\n",
        "\n",
        "# # check that annotation file has categories corresponding to model classes\n",
        "# train['categories']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrTMdgm_f2Fa"
      },
      "source": [
        "# Load Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L22zHN_onLU5"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "from mmdet.apis import inference_detector, show_result_pyplot\n",
        "from mmdet.models import build_detector\n",
        "import torch\n",
        "\n",
        "# Choose to use a config and initialize the detector\n",
        "#config = 'configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco.py'\n",
        "config = 'configs/yolo/yolov3_d53_320_273e_coco.py'\n",
        "\n",
        "# Setup a checkpoint file to load\n",
        "#checkpoint = 'checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth'\n",
        "checkpoint = 'checkpoints/yolov3_d53_320_273e_coco-421362b6.pth'\n",
        "# checkpoint = '/content/mmdetection/tutorial_exps/latest.pth'\n",
        "\n",
        "# Set the device to be used for evaluation\n",
        "device=torch.device(\"cpu\")\n",
        "\n",
        "# Load the config\n",
        "config = mmcv.Config.fromfile(config)\n",
        "# Set pretrained to be None since we do not need pretrained model here\n",
        "config.model.pretrained = None\n",
        "\n",
        "# Initialize the detector\n",
        "model = build_detector(config.model)\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = load_checkpoint(model, checkpoint, map_location=device)\n",
        "\n",
        "# Set the classes of models for inference\n",
        "model.CLASSES = checkpoint['meta']['CLASSES']\n",
        "\n",
        "# We need to set the model's cfg for inference\n",
        "model.cfg = config\n",
        "\n",
        "# Convert the model to GPU\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee-1X1epEklo"
      },
      "outputs": [],
      "source": [
        "# check that annotation file has categories corresponding to model classes\n",
        "def categories_aligned(model : model, ann_file_path: str):\n",
        "  ann_file = json.load(open(ann_file_path))\n",
        "  for categ_model, categ_file in zip(model.CLASSES, ann_file['categories']):\n",
        "    if categ_file['name'] == categ_model:\n",
        "      continue\n",
        "    else:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "print(f\"Categories in model and dataset aligned: {categories_aligned(model, 'data/coco/cityscapes/annotations/instancesonly_filtered_gtFine_train_exp1.json')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38Eq7CBdAfwD"
      },
      "outputs": [],
      "source": [
        "classes = model.CLASSES[:8]\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLTDt1S4jETg"
      },
      "source": [
        "# Load evaluation metrics object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja_6nCA_Z_8c"
      },
      "outputs": [],
      "source": [
        "!pip install mmeval\n",
        "!pip install rich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GcXB_dQmnzp"
      },
      "outputs": [],
      "source": [
        "from mmeval import COCODetection\n",
        "\n",
        "try:\n",
        "  from mmeval.metrics.utils.coco_wrapper import mask_util\n",
        "except ImportError as e:\n",
        "  mask_util = None\n",
        "\n",
        "from COCODetection import COCODetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41ADFSWQ-5bH"
      },
      "source": [
        "# Format results for mmeval input\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ7s1z0DgBz_"
      },
      "outputs": [],
      "source": [
        "def convert_result_format(result: list, img_id : int, file_name: str) -> list:\n",
        "  \"\"\"Input is the YOLO model output, which is a list of 80 arrays.\n",
        "  Each array i is the result for class i.\n",
        "  Converts to format for mmeval tool to add prediction\n",
        "  Should return a list of dicts. Each image results in a new dict\n",
        "  \"\"\"\n",
        "\n",
        "  bbox_result = result\n",
        "  # output = []\n",
        "  classes = [0,1,2,3,5,6,7] # skip airplane = 4\n",
        "  # for multiple images add for loop here and change image_id each loop\n",
        "  labels = []\n",
        "  scores = []\n",
        "  boxes = []\n",
        "  for i, dict_per_label in enumerate(bbox_result):\n",
        "    image_id = img_id    #fixed image id for now - using aachen file from demo\n",
        "    # Filter out bboxes that are predictions not from cityscapes classes\n",
        "    if i in classes:\n",
        "      label = [i]*dict_per_label.shape[0]\n",
        "      labels.append(label)\n",
        "      box = dict_per_label[:,:4]\n",
        "      boxes.append(box)\n",
        "      score = dict_per_label[:,-1]\n",
        "      scores.append(score)\n",
        "\n",
        "  labels = np.concatenate(labels)\n",
        "  bboxes = np.vstack(boxes)\n",
        "  scores = np.hstack(scores)\n",
        "\n",
        "  data = dict()\n",
        "  data['img_id'] = image_id\n",
        "  data['bboxes'] = bboxes\n",
        "  data['scores'] = scores\n",
        "  data['labels'] = labels\n",
        "  data['width'] = 2048\n",
        "  data['height'] = 1024\n",
        "\n",
        "  # fixed for now - make this dynamic\n",
        "  data['file_name']=  file_name\n",
        "  # output.append(data)\n",
        "  return data\n",
        "\n",
        "def convert_model_output(outputs : list, ann_file : str):\n",
        "  f = open(ann_file)\n",
        "  file = json.load(f)\n",
        "\n",
        "  bbox_all_images = []\n",
        "  for prediction , data in zip(outputs, file['images']):\n",
        "    img_id = data['id']\n",
        "    file_name = data['file_name']\n",
        "    per_image_result = convert_result_format(prediction, img_id , file_name)\n",
        "    bbox_all_images.append(per_image_result)\n",
        "  return bbox_all_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lRNongfpVfK"
      },
      "source": [
        "# Configure Model for Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MKqMKGU7_-1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mmcv\n",
        "from mmcv import Config\n",
        "import os.path as osp\n",
        "\n",
        "from mmdet.apis import inference_detector, show_result_pyplot\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "from mmcv.runner import EpochBasedRunner\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kas120Jqg91S"
      },
      "outputs": [],
      "source": [
        "def modify_data_config(train_file, val_file, test_file):\n",
        "    cfg = Config.fromfile('./configs/yolo/yolov3_d53_320_273e_coco_val.py')\n",
        "    # modify configuration of data\n",
        "    cfg.data.train.ann_file = '/content/mmcv-full/mmdetection/data/coco/cityscapes/annotations/'+train_file+'.json'\n",
        "    cfg.data.train.img_prefix = '/content/mmcv-full/mmdetection/data/coco/cityscapes'\n",
        "\n",
        "    cfg.data.val.ann_file = '/content/mmcv-full/mmdetection/data/coco/cityscapes/annotations/'+val_file+'.json'\n",
        "    cfg.data.val.img_prefix = '/content/mmcv-full/mmdetection/data/coco/cityscapes'\n",
        "\n",
        "    cfg.data.test.ann_file = '/content/mmcv-full/mmdetection/data/coco/cityscapes/annotations/'+test_file+'.json'\n",
        "    cfg.data.test.img_prefix = '/content/mmcv-full/mmdetection/data/coco/cityscapes'\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def set_cfg_parameters(cfg: Config, max_epochs: int, lr: float):\n",
        "    cfg.load_from = 'checkpoints/yolov3_d53_320_273e_coco-421362b6.pth'\n",
        "\n",
        "    # Set up working dir to save files and logs.\n",
        "    cfg.work_dir = './model_outputs'\n",
        "\n",
        "    # The original learning rate (LR) is set for 8-GPU training.\n",
        "    # We divide it by 8 since we only use one GPU.\n",
        "    cfg.optimizer.lr = lr / 8\n",
        "    cfg.lr_config.warmup = None\n",
        "    cfg.log_config.interval = 20\n",
        "    cfg.runner.max_epochs = max_epochs\n",
        "\n",
        "    # Change the evaluation metric since we use a customized dataset.\n",
        "    cfg.evaluation.metric = 'mAP'  # 'mAP' or 'bbox_mAP'\n",
        "    # We can set the evaluation interval to reduce the evaluation times.\n",
        "    cfg.evaluation.interval = 12\n",
        "    # We can set the checkpoint saving interval to reduce the storage cost.\n",
        "    cfg.checkpoint_config.interval = 12\n",
        "\n",
        "    # Set seed thus the results are more reproducible.\n",
        "    cfg.seed = 0\n",
        "    # set_random_seed(0, deterministic=False)\n",
        "    cfg.device = 'cuda'\n",
        "    cfg.gpu_ids = range(1)\n",
        "\n",
        "    # We can also use tensorboard to log the training process.\n",
        "    cfg.log_config.hooks = [\n",
        "        dict(type='TextLoggerHook'),\n",
        "        dict(type='TensorboardLoggerHook')]\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def build_datasets(cfg, train=True, val=False):\n",
        "    '''\n",
        "    :param cfg : configuration of model:\n",
        "    :param train: train mode with train dataset:\n",
        "    :param val: if val mode set to true then runner will calculate losses on validation set after each training epoch\n",
        "    :return:\n",
        "    '''\n",
        "    datasets = None\n",
        "    if train and val:\n",
        "        datasets = [build_dataset(cfg.data.train), build_dataset(cfg.data.val)]\n",
        "    if train and not val:\n",
        "        datasets = [build_dataset(cfg.data.train)]\n",
        "    if not train and val:\n",
        "        datasets = [build_dataset(cfg.data.val)]\n",
        "    return datasets\n",
        "\n",
        "def build_workflow(cfg, num_epochs =1, train=True, val=False, val_every_n= 1):\n",
        "        '''The only difference between [('train', 1), ('val', 1)] and [('train', 1)]\n",
        "        is that the runner will calculate losses on validation set after each training epoch.\n",
        "        Need length of workflow and dataset to be the same!\n",
        "        '''\n",
        "        workflow = None\n",
        "        if train and val:\n",
        "            workflow = [(\"train\",num_epochs), (\"val\",val_every_n)]\n",
        "        if train and not val:\n",
        "            workflow = [(\"train\",num_epochs)]\n",
        "        if not train and val:\n",
        "            workflow = [(\"val\", val_every_n)]\n",
        "        return workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTaXqOSg2FEw"
      },
      "source": [
        "# Run Experiments of Finetune Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0Fe0pkoCB5q"
      },
      "outputs": [],
      "source": [
        "from mmdet.datasets import build_dataloader\n",
        "from mmdet.utils import *\n",
        "from mmdet.apis import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OvnW3D6GJ_g"
      },
      "outputs": [],
      "source": [
        "def run_expirement(train_file, test_file, val_file, train, val, max_epochs, lr):\n",
        "\n",
        "  # create config file\n",
        "  cfg = modify_data_config(train_file, test_file, val_file)\n",
        "  cfg = set_cfg_parameters(cfg, max_epochs, lr)\n",
        "\n",
        "  # build dataset\n",
        "  datasets = build_datasets(cfg, train, val)\n",
        "\n",
        "  # buikd the detector\n",
        "  model = build_detector(cfg.model)\n",
        "  w_f = build_workflow(cfg, num_epochs=1, train=True, val=val, val_every_n=1)\n",
        "  cfg.workflow = w_f\n",
        "\n",
        "  # save the results\n",
        "  mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "  df_results = train_detector(model, datasets, cfg, distributed=False, validate=True, meta={'patience':10000})\n",
        "  df_results['lr'] = lr\n",
        "\n",
        "  # evaluation (will bw similar to all epochs as the final run)\n",
        "  test_dataloader_default_args = dict(\n",
        "          samples_per_gpu=1, workers_per_gpu=2, dist=False, shuffle=False)\n",
        "\n",
        "  test_loader_cfg = {\n",
        "          **test_dataloader_default_args,\n",
        "          **cfg.data.get('test_dataloader', {})\n",
        "      }\n",
        "\n",
        "  dataset = build_dataset(cfg.data.test)\n",
        "  data_loader = build_dataloader(dataset, **test_loader_cfg)\n",
        "  model = build_dp(model, cfg.device, device_ids=cfg.gpu_ids)\n",
        "  outputs = single_gpu_test(model, data_loader, False, None,   0.3)\n",
        "  test_path = '/content/mmcv-full/mmdetection/data/coco/cityscapes/annotations/'+test_file+'.json'\n",
        "  results = convert_model_output(outputs, test_path)\n",
        "\n",
        "  coco_det_metric = COCODetection(classes, ann_file = test_path, classwise = True )\n",
        "  coco_det_metric.add_predictions(results)\n",
        "  metrics = coco_det_metric.compute()\n",
        "\n",
        "  for key, value in metrics.items():\n",
        "    df_results[key] = value\n",
        "\n",
        "  df_results['file_names'] = train_file\n",
        "  print(\"run exp\")\n",
        "  display(df_results)\n",
        "  return df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU7EWzSsIzYP"
      },
      "outputs": [],
      "source": [
        "train_file = 'instancesonly_filtered_gtFine_dusseldorf_cologne_aachen_munster'\n",
        "test_file = 'instancesonly_filtered_gtFine_dusseldorf'\n",
        "val_file = 'instancesonly_filtered_gtFine_bochum'\n",
        "\n",
        "train=True\n",
        "val=True\n",
        "epoches = [14,20,25]#[4, 8, 10]#, 8] #, 12, 20]\n",
        "lrs = [0.002, 0.0002] # [0.02, 0.002, 0.0002]#, 0.002, 0.0002]#, 0.00002]\n",
        "\n",
        "df_results = pd.DataFrame()\n",
        "for epoch in epoches:\n",
        "  for lr in lrs:\n",
        "    df_tmp = run_expirement(train_file, test_file, val_file, train, val, epoch, lr)\n",
        "    df_tmp[['epoch','train_loss','val_loss']].set_index('epoch').plot(title = 'Experiment Results')\n",
        "    plt.show()\n",
        "\n",
        "    df_results = pd.concat([df_results, df_tmp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0590mIqi95ZV"
      },
      "outputs": [],
      "source": [
        "df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCsRfzofBdaa"
      },
      "outputs": [],
      "source": [
        "# create final results output\n",
        "df_results.to_csv('exp1_results_210623_2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "E03C-rD4EiJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aac45546-6d26-4f13-9d85-ee155e81a724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gupload\n",
            "  Downloading gupload-1.1.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting click==7.0 (from gupload)\n",
            "  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-python-client==1.7.10 (from gupload)\n",
            "  Downloading google_api_python_client-1.7.10-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.7.10->gupload) (0.21.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.7.10->gupload) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.7.10->gupload) (0.1.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.7.10->gupload) (1.16.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client==1.7.10->gupload)\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.7.10->gupload) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (0.5.0)\n",
            "Installing collected packages: uritemplate, click, google-api-python-client, gupload\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.3\n",
            "    Uninstalling click-8.1.3:\n",
            "      Successfully uninstalled click-8.1.3\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 2.2.4 requires click>=8.0, but you have click 7.0 which is incompatible.\n",
            "earthengine-api 0.1.350 requires google-api-python-client>=1.12.1, but you have google-api-python-client 1.7.10 which is incompatible.\n",
            "pip-tools 6.13.0 requires click>=8, but you have click 7.0 which is incompatible.\n",
            "typer 0.7.0 requires click<9.0.0,>=7.1.1, but you have click 7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-7.0 google-api-python-client-1.7.10 gupload-1.1.0 uritemplate-3.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "googleapiclient",
                  "uritemplate"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (1.7.10)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.90.0-py2.py3-none-any.whl (11.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.21.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (3.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.59.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.27.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
            "Installing collected packages: google-api-python-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.7.10\n",
            "    Uninstalling google-api-python-client-1.7.10:\n",
            "      Successfully uninstalled google-api-python-client-1.7.10\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gupload 1.1.0 requires google-api-python-client==1.7.10, but you have google-api-python-client 2.90.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-api-python-client-2.90.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "googleapiclient"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# save files in drive\n",
        "!pip install --upgrade gupload\n",
        "!pip install --upgrade google-api-python-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PFCNCis1Er8L"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gupload --to '19wT_UbNxyCrTY6LJVtCPOswOtjY8djyU' df_results.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snmi1zBP1hMJ"
      },
      "source": [
        "# Pull Changes from Git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu8X90IP10Qn",
        "outputId": "028c81fc-d8c7-4049-9236-ff9a966182f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/                                       MANIFEST.in\n",
            "CITATION.cff                                       \u001b[01;34mmmdet\u001b[0m/\n",
            "COCODetection.py                                   \u001b[01;34mmmdet.egg-info\u001b[0m/\n",
            "confgure_new_model.py                              model-index.yml\n",
            "\u001b[01;34mconfigs\u001b[0m/                                           \u001b[01;34mmodel_outputs\u001b[0m/\n",
            "dana_mmdetection_notebook.ipynb                    \u001b[01;34m__pycache__\u001b[0m/\n",
            "dana_mmdetection_notebook_updated.ipynb            pytest.ini\n",
            "\u001b[01;34mdata\u001b[0m/                                              README.md\n",
            "\u001b[01;34mdemo\u001b[0m/                                              README_zh-CN.md\n",
            "\u001b[01;34mdocker\u001b[0m/                                            \u001b[01;34mrequirements\u001b[0m/\n",
            "\u001b[01;34mdocs\u001b[0m/                                              requirements.txt\n",
            "exp1_results_210623.csv                            \u001b[01;34mresources\u001b[0m/\n",
            "LICENSE                                            setup.cfg\n",
            "main_mmdetection_notebook.ipynb                    \u001b[01;32msetup.py\u001b[0m*\n",
            "main_mmdetection_notebook_with_mmcv_full.ipynb     \u001b[01;34mtests\u001b[0m/\n",
            "main_mmdetection_notebook_with_mmcv_full_v2.ipynb  \u001b[01;34mtools\u001b[0m/\n",
            "main_mmdetection_notebook_with_mmcv_full_v3.ipynb\n"
          ]
        }
      ],
      "source": [
        "# %ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLJ_o4OO12sO",
        "outputId": "bebd7d22-9696-4fb9-af50-2442772765c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmcv-full\n"
          ]
        }
      ],
      "source": [
        "# %cd -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG1tCikH147r",
        "outputId": "5422c34c-9196-4130-caf1-a244f283dba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# !git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc2scbGW19_n",
        "outputId": "c24f281e-dd33-42b6-cdd7-34351b4864c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmcv-full/mmdetection\n"
          ]
        }
      ],
      "source": [
        "# %cd mmdetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nenAZ7YQE0NE"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "85qWWHIHEzfS"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# import os\n",
        "\n",
        "# logs_dir = \"/content/mmcvfull/mmdetection/model_outputs/tf_logs/events.out.tfevents.1684235984.8fb6c866f081.2985.1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dXe2t81XE9CO"
      },
      "outputs": [],
      "source": [
        "# summary_writer = tf.summary.create_file_writer(logs_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qEIAnwPbFJ-P"
      },
      "outputs": [],
      "source": [
        "# with summary_writer.as_default():\n",
        "#     tf.summary.scalar(\"val_loss\", loss, step=epoch)\n",
        "#     # tf.summary.scalar(\"accuracy\", accuracy, step=epoch)\n",
        "#     # tf.summary.histogram(\"weights\", weights, step=epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4I_uSA2F_AA"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCXa67bjFWDN"
      },
      "outputs": [],
      "source": [
        "# %tensorboard --logdir {logs_dir} #--port=6007"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnE1fA_XGwv1"
      },
      "outputs": [],
      "source": [
        "!lsof -i :6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq1DWJBfaDG-"
      },
      "outputs": [],
      "source": [
        "# !git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii52mT2iaLJr"
      },
      "outputs": [],
      "source": [
        "# !git add --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsJem_aQa_4C"
      },
      "outputs": [],
      "source": [
        "# !git commit -a -m \"Added files for Finetuning with Validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eg46nsjbMxk"
      },
      "outputs": [],
      "source": [
        "# !git remote -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKhqzwN4bTgD"
      },
      "outputs": [],
      "source": [
        "# !git push origin master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3Nd3HVAbvRO"
      },
      "outputs": [],
      "source": [
        "# token = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxI9vX0ccEyT"
      },
      "source": [
        "# Graph of results with similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7LsU42THSQe"
      },
      "outputs": [],
      "source": [
        "# to do\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "i16HTIRxVM3V",
        "9gYaRY7PkGby",
        "AaKpkVXufxl6",
        "eQ6Qy2_9fF9l",
        "MrTMdgm_f2Fa",
        "LLTDt1S4jETg",
        "41ADFSWQ-5bH",
        "1lRNongfpVfK",
        "sXk_VL4ZH3FC",
        "O7R7LMVAGwSf",
        "wUabRmH4f8nL",
        "snmi1zBP1hMJ",
        "nenAZ7YQE0NE",
        "cxI9vX0ccEyT"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}